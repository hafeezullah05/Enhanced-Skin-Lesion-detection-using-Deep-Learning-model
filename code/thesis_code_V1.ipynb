{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from natsort import natsorted # type: ignore\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score as skl_precision_score\n",
    "from sklearn.metrics import recall_score as skl_recall_score\n",
    "from sklearn.metrics import f1_score as skl_f1_score\n",
    "from sklearn.metrics import accuracy_score as skl_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import the code from all .py files\n",
    "\n",
    "from custom_dataset import CustomMelanomaDataset  # Import the custom dataset\n",
    "from resnet_model import ResNetModel\n",
    "from preprocessing_csv import PreprocessingCSV\n",
    "from train_test_loop import train_and_test\n",
    "from interactive_visual_comparison import load_metadata, interactive_visual_comparison\n",
    "\n",
    "\n",
    "\n",
    "#import torch.profiler\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#from tensorboardX import SummaryWriter\n",
    "#from torch.profiler import profile, ProfilerActivity\n",
    "#import tkinter as tk\n",
    "#from tkinter import filedialog, messagebox\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dynamic root path\n",
    "BASE_DIR = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "root_path = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "\n",
    "\n",
    "# Create the full path to the CSV file\n",
    "csv_path = os.path.join(BASE_DIR, 'Thesis_Hafeez/Dataset/Train_JPEG/ISIC_2020_Training_GroundTruth.csv')\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Display the structure of the dataset\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the universal path handling logic\n",
    "BASE_DIR = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "SPLIT_CSV_DIR = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'split_csv')\n",
    "\n",
    "# Universal Path Setup for Images\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'Train_JPEG', 'JPEG')\n",
    "\n",
    "# Paths for Train/Test CSVs\n",
    "TRAIN_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'split_csv', 'train_split.csv')\n",
    "TEST_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'split_csv', 'test_split.csv')\n",
    "\n",
    "# Create the full path to the CSV file\n",
    "CSV_PATH = os.path.join(root_path, 'Thesis_Hafeez/Dataset/Train_JPEG/ISIC_2020_Training_GroundTruth.csv')\n",
    "preprocess_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez/Dataset/Train_JPEG/ISIC_2020_Training_GroundTruth_preprocess.csv')\n",
    "\n",
    "\n",
    "MODEL_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez',  'Thesis_Code/Enhanced-Skin-Lesion-detection-using-Deep-Learning-model/results', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step : Create an instance of PreprocessingCSV\n",
    "preprocessor = PreprocessingCSV(CSV_PATH, BASE_DIR)\n",
    "\n",
    "# Step : Execute the preprocessing steps\n",
    "preprocessor.analyze_raw_data()\n",
    "preprocessor.check_for_anomalies()\n",
    "preprocessor.clean_data()\n",
    "preprocessor.save_clean_data()\n",
    "preprocessor.split_by_patient_id()\n",
    "preprocessor.verify_preprocessed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transforms for image augmentation and normalization\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size (224x224)\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally for data augmentation\n",
    "    transforms.RandomVerticalFlip(),    # Randomly flip the image vertically\n",
    "    transforms.ToTensor(),  # Convert PIL Image or numpy.ndarray to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images with pre-defined mean and std\n",
    "])\n",
    "\n",
    "# Define transformations for testing\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size (224x224)\n",
    "    transforms.ToTensor(),  # Convert PIL Image or numpy.ndarray to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images with pre-defined mean and std\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define train and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize datasets\n",
    "# Create datasets\n",
    "train_dataset = CustomMelanomaDataset(\n",
    "    csv_file=TRAIN_CSV_PATH,\n",
    "    image_dir=IMAGE_DIR,\n",
    "    transform=train_transforms,\n",
    "    is_test=False  # Indicates that this dataset is for training\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "test_dataset = CustomMelanomaDataset(\n",
    "    csv_file=TEST_CSV_PATH,\n",
    "    image_dir=IMAGE_DIR,\n",
    "    transform=test_transforms,\n",
    "    is_test=True  # Indicates that this dataset is for testing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameters\n",
    "lr = 1e-4\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "num_workers=4\n",
    "\n",
    "# Determine if CUDA is available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "PIN_MEMORY = True if torch.cuda.is_available() else False\n",
    "\n",
    "print(f\"[INFO] Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataloaders, lossFunc, Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,  # Shuffle the data for training\n",
    "    num_workers=num_workers,  # Number of workers for data loading\n",
    "    pin_memory=PIN_MEMORY  # Use pin memory if using CUDA\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # No need to shuffle test data\n",
    "    num_workers=num_workers,  # Number of workers for data loading\n",
    "    pin_memory=PIN_MEMORY  # Use pin memory if using CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps per epoch\n",
    "trainSteps = len(train_loader)\n",
    "testSteps = len(test_loader)\n",
    "\n",
    "print(f\"[INFO] Training steps per epoch: {trainSteps}\")\n",
    "print(f\"[INFO] Testing steps per epoch: {testSteps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Initialize Model, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for weighted cross entropy\n",
    "benign_count = len(train_dataset.metadata[train_dataset.metadata['benign_malignant'] == 'benign'])\n",
    "\n",
    "malignant_count = len(train_dataset.metadata[train_dataset.metadata['benign_malignant'] == 'malignant'])\n",
    "\n",
    "# Adjust weight for handling class imbalance\n",
    "pos_weight = torch.tensor([benign_count / malignant_count], dtype=torch.float).to(DEVICE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, where we pass the number of metadata features (3 in this case)\n",
    "num_metadata_features = 3  # Number of metadata features: sex, age, and site\n",
    "model = ResNetModel(num_metadata_features).to(DEVICE)\n",
    "\n",
    "# Loss function and optimizer\n",
    "lossFunc = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Learning rate scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Training History Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Training Loop Implementation with Metric Tracking and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the training and test loop\n",
    "H = train_and_test(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    lossFunc=lossFunc,\n",
    "    DEVICE=DEVICE,\n",
    "    NUM_EPOCHS=NUM_EPOCHS\n",
    ")\n",
    "\n",
    "# After training, we can use H for further analysis or plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the training loop ends, save the model\n",
    "# Ensure the directory exists, if not, create it\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "\n",
    "# Define the model filename with the .pth extension\n",
    "model_filename = \"melanoma_trained_model.pth\"\n",
    "\n",
    "# Full path to save the model\n",
    "model_save_path = os.path.join(MODEL_PATH, model_filename)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Training Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(H):\n",
    "    epochs = range(1, len(H[\"train_loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(16, 20))\n",
    "\n",
    "    # Plot Training and Test Loss\n",
    "    plt.subplot(4, 2, 1)\n",
    "    plt.plot(epochs, H[\"train_loss\"], 'b', label='Train Loss')\n",
    "    plt.plot(epochs, H[\"test_loss\"], 'r', label='Test Loss')\n",
    "    plt.title('Training and Test Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training and Test Accuracy\n",
    "    plt.subplot(4, 2, 2)\n",
    "    plt.plot(epochs, H[\"train_acc\"], 'b', label='Train Accuracy')\n",
    "    plt.plot(epochs, H[\"test_acc\"], 'r', label='Test Accuracy')\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training and Test Precision\n",
    "    plt.subplot(4, 2, 3)\n",
    "    plt.plot(epochs, H[\"train_precision\"], 'b', label='Train Precision')\n",
    "    plt.plot(epochs, H[\"test_precision\"], 'r', label='Test Precision')\n",
    "    plt.title('Training and Test Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training and Test Recall\n",
    "    plt.subplot(4, 2, 4)\n",
    "    plt.plot(epochs, H[\"train_recall\"], 'b', label='Train Recall')\n",
    "    plt.plot(epochs, H[\"test_recall\"], 'r', label='Test Recall')\n",
    "    plt.title('Training and Test Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training and Test F1 Score\n",
    "    plt.subplot(4, 2, 5)\n",
    "    plt.plot(epochs, H[\"train_f1\"], 'b', label='Train F1 Score')\n",
    "    plt.plot(epochs, H[\"test_f1\"], 'r', label='Test F1 Score')\n",
    "    plt.title('Training and Test F1 Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training and Test ROC AUC\n",
    "    plt.subplot(4, 2, 6)\n",
    "    plt.plot(epochs, H[\"train_roc_auc\"], 'b', label='Train ROC AUC')\n",
    "    plt.plot(epochs, H[\"test_roc_auc\"], 'r', label='Test ROC AUC')\n",
    "    plt.title('Training and Test ROC AUC')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    plt.subplot(4, 2, 7)\n",
    "    for i, (precision, recall) in enumerate(H[\"test_precision_recall_curve\"]):\n",
    "        plt.plot(recall, precision, label=f'Epoch {i+1}')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Average Precision Score\n",
    "    plt.subplot(4, 2, 8)\n",
    "    plt.plot(epochs, H[\"test_average_precision\"], 'b', label='Test Average Precision')\n",
    "    plt.title('Average Precision Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Average Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the metrics\n",
    "plot_metrics(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save the plot to the specified path\n",
    "plot_filename = os.path.join(MODEL_PATH, \"training_metrics_plot.png\")\n",
    "\n",
    "# Use a higher DPI for better quality\n",
    "plt.savefig(plot_filename, format='png', dpi=300)  # Save the plot with higher DPI for clarity\n",
    "print(f\"Plot saved to {plot_filename}\")\n",
    "    \n",
    "plt.close()  # Ensure the plot is cleared after saving to avoid showing it blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for Train/Test CSVs\n",
    "TRAIN_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'split_csv', 'train_split.csv')\n",
    "TEST_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'split_csv', 'test_split.csv')\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)  # Load train csv dataset\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)  # Load test csv dataset\n",
    "\n",
    "print(\"Target label count in training....\")\n",
    "print(df_train['target'].value_counts())  # Replace 'label_column' with the name of the column containing class labels\n",
    "\n",
    "print(\"Target label count in testing....\")\n",
    "print(df_test['target'].value_counts())  # Replace 'label_column' with the name of the column containing class labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interactive visual comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata\n",
    "TEST_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'split_csv', 'test_split.csv')\n",
    "test_metadata_df = load_metadata(TEST_CSV_PATH)\n",
    "\n",
    "# Run the interactive visual comparison function\n",
    "interactive_visual_comparison(model, test_loader, DEVICE, test_metadata_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the test CSV to get metadata information\n",
    "def load_metadata(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# Define Function for Interactive Visual Comparison of 20 Random Images\n",
    "def interactive_visual_comparison(model, test_loader, device, test_metadata_df):\n",
    "    model.eval()\n",
    "    all_images = []\n",
    "    all_image_names = []\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    transform_back = transforms.ToPILImage()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, metadata, targets, image_names in test_loader:\n",
    "            images, metadata = images.to(device), metadata.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Make predictions\n",
    "            outputs = model(images, metadata)\n",
    "            preds = torch.sigmoid(outputs).round()  # Convert logits to binary predictions (0 or 1)\n",
    "            \n",
    "            # Store images, image names, targets, and predictions\n",
    "            all_images.extend(images.cpu().detach())\n",
    "            all_image_names.extend(image_names)  # Use the image names directly\n",
    "            all_targets.extend(targets.cpu().detach().numpy())\n",
    "            all_preds.extend(preds.cpu().detach().numpy())\n",
    "    \n",
    "    # Randomly select 20 samples\n",
    "    indices = random.sample(range(len(all_images)), 20)\n",
    "    \n",
    "    plt.figure(figsize=(20, 40))\n",
    "    for i, idx in enumerate(indices):\n",
    "        img_name = all_image_names[idx]\n",
    "        original_label = \"malignant\" if all_targets[idx] == 1 else \"benign\"\n",
    "        predicted_label = \"malignant\" if all_preds[idx] == 1 else \"benign\"\n",
    "\n",
    "        # Fetch metadata from the CSV file\n",
    "        meta_row = test_metadata_df[test_metadata_df['image_name'] == img_name]\n",
    "\n",
    "        if meta_row.empty:\n",
    "            print(f\"Warning: Metadata for image '{img_name}' not found.\")\n",
    "            benign_malignant = \"unknown\"\n",
    "            target = -1  # Use a placeholder value for target\n",
    "        else:\n",
    "            benign_malignant = meta_row['benign_malignant'].values[0]\n",
    "            target = int(meta_row['target'].values[0])\n",
    "\n",
    "        # Convert image tensor back to PIL image\n",
    "        img = transform_back(all_images[idx])\n",
    "        \n",
    "        # Plot the image and metadata\n",
    "        plt.subplot(10, 2, i * 2 + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Image: {img_name}\")\n",
    "\n",
    "        # Plot metadata and prediction details\n",
    "        plt.subplot(10, 2, i * 2 + 2)\n",
    "        plt.axis('off')\n",
    "        plt.text(0.1, 0.8, f\"Original: {benign_malignant} (Target: {target})\", fontsize=12)\n",
    "        plt.text(0.1, 0.6, f\"Predicted: {predicted_label} (Predicted Target: {int(all_preds[idx])})\", fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load the metadata\n",
    "TEST_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'split_csv', 'test_split.csv')\n",
    "test_metadata_df = load_metadata(TEST_CSV_PATH)\n",
    "\n",
    "# Run the interactive visual comparison function\n",
    "interactive_visual_comparison(model, test_loader, DEVICE, test_metadata_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
