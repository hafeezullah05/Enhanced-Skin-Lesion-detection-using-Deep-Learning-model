{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed and working!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import torchvision.transforms as transforms\n",
    "from tkinter import ttk\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnetB7_model import EfficientNetB7Model  # Import my custom model class\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(\"All required libraries are installed and working!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .pth module compatible loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "Detected 'module.' prefix in keys. Cleaning state_dict...\n",
      "Model loaded successfully with strict=True.\n"
     ]
    }
   ],
   "source": [
    "# Function to remove `module.` prefix from keys\n",
    "def remove_module_prefix(state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace(\"module.\", \"\")  # Remove `module.` prefix\n",
    "        new_state_dict[new_key] = v\n",
    "    return new_state_dict\n",
    "\n",
    "# Define the base directory and model path\n",
    "BASE_DIR = \"/Users/hafeez/Desktop\"\n",
    "MODEL_PATH = os.path.join(\n",
    "    BASE_DIR, 'Thesis_Hafeez', 'Thesis_Code', \n",
    "    'Enhanced-Skin-Lesion-detection-using-Deep-Learning-model', \n",
    "    'results', 'output', 'efficientnetb7_trained_model.pth'\n",
    ")\n",
    "\n",
    "# Ensure compatibility with CPU-only systems\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the custom model with the correct metadata features count\n",
    "num_metadata_features = 3  # Number of metadata features: sex, age, and anatomy\n",
    "model = EfficientNetB7Model(num_metadata_features)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the state_dict from the checkpoint\n",
    "try:\n",
    "    # Check if the model path exists\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"Error: Model path does not exist at {MODEL_PATH}\")\n",
    "        raise FileNotFoundError(f\"{MODEL_PATH} not found.\")\n",
    "\n",
    "    # Attempt to load the checkpoint\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    \n",
    "    # Clean the state_dict by removing 'module.' prefix if it exists\n",
    "    if any(key.startswith(\"module.\") for key in checkpoint.keys()):\n",
    "        print(\"Detected 'module.' prefix in keys. Cleaning state_dict...\")\n",
    "        checkpoint = remove_module_prefix(checkpoint)\n",
    "\n",
    "    # Check if checkpoint keys match the model keys\n",
    "    checkpoint_keys = set(checkpoint.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    if checkpoint_keys != model_keys:\n",
    "        print(\"Warning: Mismatched keys detected between checkpoint and model.\")\n",
    "        print(\"Mismatched keys:\", checkpoint_keys.difference(model_keys))\n",
    "    \n",
    "    # Try strict loading with the cleaned state_dict\n",
    "    try:\n",
    "        model.load_state_dict(checkpoint, strict=True)\n",
    "        print(\"Model loaded successfully with strict=True.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Strict loading failed. Error:\", e)\n",
    "        print(\"Attempting to load with strict=False...\")\n",
    "        model.load_state_dict(checkpoint, strict=False)\n",
    "        print(\"Model loaded successfully with strict=False. Warning: Verify mismatched keys.\")\n",
    "    \n",
    "    # Save the cleaned model only if 'module.' was present\n",
    "    if any(key.startswith(\"module.\") for key in checkpoint.keys()):\n",
    "        CLEANED_MODEL_PATH = os.path.join(\n",
    "            BASE_DIR, 'Thesis_Hafeez', 'Thesis_Code', \n",
    "            'Enhanced-Skin-Lesion-detection-using-Deep-Learning-model', \n",
    "            'results', 'output', 'efficientnetb7_cleaned_model.pth'\n",
    "        )\n",
    "        torch.save(model.state_dict(), CLEANED_MODEL_PATH)\n",
    "        print(f\"Cleaned model saved at {CLEANED_MODEL_PATH}\")\n",
    "\n",
    "except FileNotFoundError as fnfe:\n",
    "    print(f\"Checkpoint file not found at {MODEL_PATH}. Error: {fnfe}\")\n",
    "except Exception as ex:\n",
    "    print(f\"An error occurred: {ex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory and paths\n",
    "BASE_DIR = \"/Users/hafeez/Desktop\"\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'Predictions', 'ISIC_2020_Test')\n",
    "PRED_CSV_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Dataset', 'Predictions', 'ISIC_2020_Test_Metadata.csv')\n",
    "CLEANED_MODEL_PATH = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Thesis_Code', \n",
    "                                   'Enhanced-Skin-Lesion-detection-using-Deep-Learning-model', \n",
    "                                   'results', 'output', 'efficientnetb7_cleaned_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "Custom model loaded and ready for inference.\n"
     ]
    }
   ],
   "source": [
    "from efficientnetB7_model import EfficientNetB7Model  # Import your custom model\n",
    "\n",
    "# Device setup\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize your custom model with the correct number of metadata features\n",
    "num_metadata_features = 3  # Adjust this based on your use case\n",
    "model = EfficientNetB7Model(num_metadata_features)\n",
    "\n",
    "# Ensure compatibility with your device\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Load the state_dict\n",
    "checkpoint = torch.load(CLEANED_MODEL_PATH, map_location=DEVICE)\n",
    "\n",
    "# Load the weights into your model\n",
    "model.load_state_dict(checkpoint, strict=True)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Custom model loaded and ready for inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Metadata and Define Image Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded successfully.\n",
      "Transformations defined for image preprocessing.\n"
     ]
    }
   ],
   "source": [
    "# Load metadata CSV\n",
    "try:\n",
    "    ground_truth_df = pd.read_csv(PRED_CSV_PATH)\n",
    "    print(\"Metadata loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Metadata CSV not found at {PRED_CSV_PATH}\")\n",
    "    raise\n",
    "\n",
    "# Define the transform for input images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "print(\"Transformations defined for image preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for sex and anatomy categories\n",
    "sex_mapping = {\n",
    "    'male': 0,\n",
    "    'female': 1\n",
    "}\n",
    "\n",
    "anatomy_mapping = {\n",
    "    'head/neck': 0,\n",
    "    'torso': 1,\n",
    "    'lower extremity': 2,\n",
    "    'upper extremity': 3,\n",
    "    'palms/soles': 4,\n",
    "    'oral/genital': 5,\n",
    "    # Add more mappings as needed based on your data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions for Prediction and Metadata Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict image using the model\n",
    "def predict_image(image_path, metadata):\n",
    "    try:\n",
    "        # Load and transform the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = transform(image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # Prepare metadata tensor\n",
    "        age, sex, anatomy = metadata\n",
    "        if age is None or sex is None or anatomy is None:\n",
    "            raise ValueError(f\"Incomplete metadata for image: {os.path.basename(image_path)}\")\n",
    "\n",
    "        # Map metadata to tensor values\n",
    "        metadata_tensor = torch.tensor(\n",
    "            [[age, sex_mapping.get(sex, -1), anatomy_mapping.get(anatomy, -1)]]\n",
    "        ).float().to(DEVICE)\n",
    "\n",
    "        # Perform prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor, metadata_tensor).squeeze()\n",
    "            probability = torch.sigmoid(output).item()\n",
    "            if not (0.0 <= probability <= 1.0): \n",
    "                raise ValueError(f\"Invalid probability value: {probability}\")\n",
    "            return probability\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get metadata from CSV\n",
    "def get_metadata(image_name):\n",
    "    try:\n",
    "        # Match the image name with the metadata\n",
    "        ground_truth_row = ground_truth_df[ground_truth_df['image_name'] == image_name]\n",
    "        if not ground_truth_row.empty:\n",
    "            # Extract metadata fields\n",
    "            age = ground_truth_row.iloc[0]['age_approx']\n",
    "            sex = ground_truth_row.iloc[0]['sex']\n",
    "            anatomy = ground_truth_row.iloc[0]['anatom_site_general']\n",
    "\n",
    "            # Handle missing values or unknown fields\n",
    "            if pd.isna(age) or pd.isna(sex) or pd.isna(anatomy):\n",
    "                print(f\"Warning: Missing metadata for image: {image_name}\")\n",
    "                return None, None, None\n",
    "\n",
    "            return age, sex, anatomy\n",
    "        else:\n",
    "            print(f\"Warning: Image not found in metadata CSV: {image_name}\")\n",
    "            return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing metadata: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Setup for Multi-Image Selection and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate final prediction based on hybrid approach\n",
    "def calculate_final_prediction(probabilities):\n",
    "    \"\"\"\n",
    "    Calculates the final prediction based on average probability and high-confidence predictions.\n",
    "    \"\"\"\n",
    "    if not probabilities:\n",
    "        raise ValueError(\"Probability list is empty. Cannot calculate final prediction.\")\n",
    "    \n",
    "    avg_probability = sum(probabilities) / len(probabilities)\n",
    "    high_confidence_exists = any(prob > 0.9 for prob in probabilities)\n",
    "\n",
    "    # Final decision logic\n",
    "    if high_confidence_exists and avg_probability > 0.5:\n",
    "        return 'malignant'\n",
    "    elif avg_probability > 0.5:\n",
    "        return 'malignant'\n",
    "    else:\n",
    "        return 'benign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old approach\n",
    "'''''\n",
    "# GUI for multi-image selection and prediction\n",
    "def select_images():\n",
    "    # Ask user to select multiple images\n",
    "    file_paths = filedialog.askopenfilenames(initialdir=IMAGE_DIR, title=\"Select Images\",\n",
    "                                             filetypes=[(\"All files\", \"*.*\")])\n",
    "    if file_paths:\n",
    "        try:\n",
    "            probabilities = []\n",
    "            result_text = \"\"\n",
    "\n",
    "            for file_path in file_paths:\n",
    "                # Get the image name (with extension)\n",
    "                image_name = os.path.basename(file_path)\n",
    "\n",
    "                # Fetch metadata from CSV\n",
    "                metadata = get_metadata(image_name)\n",
    "\n",
    "                # Ensure metadata exists\n",
    "                if None in metadata:\n",
    "                    result_text += f\"\\nError: Metadata missing for {image_name}. Skipping.\"\n",
    "                    continue\n",
    "\n",
    "                # Make prediction\n",
    "                probability = predict_image(file_path, metadata)\n",
    "                if probability is not None:\n",
    "                    probabilities.append(probability)\n",
    "                    age, sex, anatomy = metadata\n",
    "\n",
    "                    # Map numerical metadata back to categorical values for display\n",
    "                    sex_str = next((key for key, value in sex_mapping.items() if value == sex_mapping[sex]), \"Unknown\")\n",
    "                    anatomy_str = next((key for key, value in anatomy_mapping.items() if value == anatomy_mapping[anatomy]), \"Unknown\")\n",
    "\n",
    "                    result_text += (\n",
    "                        f\"\\nImage: {image_name} | \"\n",
    "                        f\"Probability: {probability:.2f} | \"\n",
    "                        f\"Metadata: Age: {age}, Sex: {sex_str}, Anatomy: {anatomy_str}\"\n",
    "                    )\n",
    "\n",
    "            # Calculate final prediction\n",
    "            if probabilities:\n",
    "                final_prediction = calculate_final_prediction(probabilities)\n",
    "                result_text += f\"\\n\\nFinal Prediction: {final_prediction.capitalize()}\"\n",
    "\n",
    "            # Update the result label\n",
    "            result_label.config(text=result_text, justify='left', font=('Helvetica', 12), foreground='#003366')\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "# Set up the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Skin Lesion Classification Tool\")\n",
    "root.geometry(\"800x900\")\n",
    "root.configure(bg='#e6f2ff')\n",
    "\n",
    "# Title label\n",
    "title_label = ttk.Label(root, text=\"Skin Lesion Classification Tool\", font=('Helvetica', 20, 'bold'), background='#e6f2ff')\n",
    "title_label.pack(pady=20)\n",
    "\n",
    "# Image display panel\n",
    "panel = tk.Label(root, bg='#e6f2ff', borderwidth=2, relief=\"groove\")\n",
    "panel.pack(pady=20)\n",
    "\n",
    "# Button to select images\n",
    "btn = ttk.Button(root, text=\"Select Images\", command=select_images)\n",
    "btn.pack(pady=10)\n",
    "\n",
    "# Label to display prediction and ground truth\n",
    "result_label = ttk.Label(root, text=\"\", wraplength=700)\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Add university logo\n",
    "try:\n",
    "    logo_path = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Thesis_Code', 'Enhanced-Skin-Lesion-detection-using-Deep-Learning-model', 'results', 'uds.jpg')\n",
    "    logo_image = Image.open(logo_path).resize((220, 150), Image.LANCZOS)  # Use LANCZOS for resizing\n",
    "    logo_photo = ImageTk.PhotoImage(logo_image)\n",
    "    logo_label = tk.Label(root, image=logo_photo, bg='#e6f2ff')\n",
    "    logo_label.image = logo_photo\n",
    "    logo_label.pack(side='bottom', pady=20)\n",
    "except (FileNotFoundError, OSError) as e:\n",
    "    print(f\"Error loading university logo: {e}\")\n",
    "\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()\n",
    "'''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the main Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Skin Lesion Classification Tool\")\n",
    "root.geometry(\"900x1000\")\n",
    "root.configure(bg='#e6f2ff')\n",
    "\n",
    "# GUI for multi-image selection and prediction\n",
    "def select_images():\n",
    "    file_paths = filedialog.askopenfilenames(\n",
    "        initialdir=IMAGE_DIR,\n",
    "        title=\"Select Images\",\n",
    "        filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")]  # Allow common image formats\n",
    "    )\n",
    "    if file_paths:\n",
    "        try:\n",
    "            # Clear existing widgets in the predictions frame\n",
    "            for widget in predictions_frame.winfo_children():\n",
    "                widget.destroy()\n",
    "\n",
    "            probabilities = []\n",
    "            images_metadata = []\n",
    "            grid_entries = []  # To ensure all selected images are displayed, even with missing metadata\n",
    "\n",
    "            for file_path in file_paths:\n",
    "                image_name = os.path.basename(file_path)\n",
    "                metadata = get_metadata(image_name)\n",
    "\n",
    "                if None in metadata:\n",
    "                    # Include the image with a missing metadata warning\n",
    "                    grid_entries.append({\n",
    "                        'image_name': image_name,\n",
    "                        'probability': None,\n",
    "                        'age': None,\n",
    "                        'sex': None,\n",
    "                        'anatomy': None,\n",
    "                        'file_path': file_path,\n",
    "                        'warning': f\"Metadata missing for {image_name}. Skipping prediction.\"\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                probability = predict_image(file_path, metadata)\n",
    "                if probability is not None:\n",
    "                    probabilities.append(probability)\n",
    "                    age, sex, anatomy = metadata\n",
    "\n",
    "                    sex_str = next((key for key, value in sex_mapping.items() if value == sex_mapping[sex]), \"Unknown\")\n",
    "                    anatomy_str = next((key for key, value in anatomy_mapping.items() if value == anatomy_mapping[anatomy]), \"Unknown\")\n",
    "\n",
    "                    grid_entries.append({\n",
    "                        'image_name': image_name,\n",
    "                        'probability': probability,\n",
    "                        'age': age,\n",
    "                        'sex': sex_str,\n",
    "                        'anatomy': anatomy_str,\n",
    "                        'file_path': file_path,\n",
    "                        'warning': None\n",
    "                    })\n",
    "\n",
    "            # Display predictions in a grid\n",
    "            num_columns = 3  # Adjust this for the desired number of columns\n",
    "            for idx, data in enumerate(grid_entries):\n",
    "                row = idx // num_columns\n",
    "                col = idx % num_columns\n",
    "\n",
    "                frame = tk.Frame(predictions_frame, bg='#e6f2ff', relief='groove', borderwidth=1)\n",
    "                frame.grid(row=row, column=col, padx=10, pady=10, sticky='nsew')\n",
    "\n",
    "                # Display image thumbnail\n",
    "                img = Image.open(data['file_path']).resize((100, 100), Image.LANCZOS)\n",
    "                img_thumbnail = ImageTk.PhotoImage(img)\n",
    "                img_label = tk.Label(frame, image=img_thumbnail, bg='#e6f2ff')\n",
    "                img_label.image = img_thumbnail\n",
    "                img_label.pack()\n",
    "\n",
    "                # Display metadata and probability or warning\n",
    "                if data['warning']:\n",
    "                    text = f\"Image: {data['image_name']}\\n{data['warning']}\"\n",
    "                    tk.Label(frame, text=text, font=('Helvetica', 12), bg='#e6f2ff', fg='red', justify='center').pack()\n",
    "                else:\n",
    "                    text = (f\"Image: {data['image_name']}\\n\"\n",
    "                            f\"Probability: {data['probability']:.2f}\\n\"\n",
    "                            f\"Age: {data['age']}, Sex: {data['sex']}, Anatomy: {data['anatomy']}\")\n",
    "                    tk.Label(frame, text=text, font=('Helvetica', 12), bg='#e6f2ff', justify='center').pack()\n",
    "\n",
    "            # Calculate and display final prediction\n",
    "            if probabilities:\n",
    "                final_prediction = calculate_final_prediction(probabilities)\n",
    "                final_prediction_text = f\"Final Prediction: {final_prediction.capitalize()}\"\n",
    "                tk.Label(predictions_frame, text=final_prediction_text,\n",
    "                         font=('Helvetica', 16, 'bold'), fg='#003366', bg='#e6f2ff').grid(\n",
    "                    row=(len(grid_entries) // num_columns) + 1, column=0, columnspan=num_columns, pady=10)\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "# Scrollable frame setup\n",
    "scrollbar_canvas = tk.Canvas(root, bg='#e6f2ff')\n",
    "scrollbar_frame = tk.Frame(scrollbar_canvas, bg='#e6f2ff')\n",
    "scrollbar = tk.Scrollbar(root, orient='vertical', command=scrollbar_canvas.yview)\n",
    "scrollbar_canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar_canvas.pack(side='left', fill='both', expand=True)\n",
    "scrollbar.pack(side='right', fill='y')\n",
    "\n",
    "scrollbar_window = scrollbar_canvas.create_window((0, 0), window=scrollbar_frame, anchor=\"nw\")\n",
    "\n",
    "def on_frame_configure(event):\n",
    "    scrollbar_canvas.configure(scrollregion=scrollbar_canvas.bbox(\"all\"))\n",
    "\n",
    "scrollbar_frame.bind(\"<Configure>\", on_frame_configure)\n",
    "\n",
    "# Predictions frame inside the scrollable area\n",
    "predictions_frame = tk.Frame(scrollbar_frame, bg='#e6f2ff')\n",
    "predictions_frame.pack(fill='both', expand=True)\n",
    "\n",
    "# Button to select images\n",
    "btn = ttk.Button(root, text=\"Select Images\", command=select_images)\n",
    "btn.pack(pady=10)\n",
    "\n",
    "# Add university logo\n",
    "try:\n",
    "    logo_path = os.path.join(BASE_DIR, 'Thesis_Hafeez', 'Thesis_Code', 'Enhanced-Skin-Lesion-detection-using-Deep-Learning-model', 'results', 'uds.jpg')\n",
    "    logo_image = Image.open(logo_path).resize((220, 150), Image.LANCZOS)\n",
    "    logo_photo = ImageTk.PhotoImage(logo_image)\n",
    "    logo_label = tk.Label(root, image=logo_photo, bg='#e6f2ff')\n",
    "    logo_label.image = logo_photo\n",
    "    logo_label.pack(side='bottom', pady=20)\n",
    "except (FileNotFoundError, OSError) as e:\n",
    "    print(f\"Error loading university logo: {e}\")\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
